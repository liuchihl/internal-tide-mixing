#!/bin/bash
#SBATCH --job-name="tilt-3D-FFT-0.008" 
#SBATCH --output="output_message/3D-idealized_tilt.%j.%N.out"
#SBATCH --partition=gpuH200x8 #gpuA100x4 ##gpuH200x8
#SBATCH --mem=36G
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1 # could be 1 for py-torch
#SBATCH --cpus-per-task=4   # spread out to use 1 core per numa, set to 64 if tasks is 1
##SBATCH --constraint="scratch"
#SBATCH --gpus-per-node=1
##SBATCH --gpu-bind=closest   # select a cpu close to gpu on pci bus topology
#SBATCH --account=bcpi-delta-gpu    # <- match to a "Project" returned by the "accounts" command
#SBATCH --mail-user=chihlul1@uci.edu
#SBATCH --mail-type="BEGIN,END" 
#SBATCH -t 48:00:00

module restore internal-tide
export PATH=$HOME/software/julia/current/bin:$PATH
date
rundir1=/scratch/bcpi/cliu28/internal-tide-mixing/run/internal_tide_3Drun_0.008.jl
rundir2=/scratch/bcpi/cliu28/internal-tide-mixing/run/internal_tide_3Drun_0.jl

# Run fix_cuda.jl first
echo "Running CUDA fix script..."
fixfile=/scratch/bcpi/cliu28/internal-tide-mixing/fix_cuda.jl
julia --project $fixfile
echo "Launching parallel Julia jobs on same GPU..."

# julia --project $rundir1
CUDA_VISIBLE_DEVICES=0 julia --project=/scratch/bcpi/cliu28/internal-tide-mixing $rundir1 > output_message/3D-idealized_tilt.run1.${SLURM_JOB_ID}.${SLURM_NODELIST}.log 2>&1 &
CUDA_VISIBLE_DEVICES=0 julia --project=/scratch/bcpi/cliu28/internal-tide-mixing $rundir2 > output_message/3D-idealized_tilt.run2.${SLURM_JOB_ID}.${SLURM_NODELIST}.log 2>&1 &
# # CUDA_VISIBLE_DEVICES=0 julia --project=/scratch/bcpi/cliu28/internal-tide-mixing $rundir3 > output_message/2D-idealized_tilt.run3.${SLURM_JOB_ID}.${SLURM_NODELIST}.log 2>&1 &
# # CUDA_VISIBLE_DEVICES=0 julia --project=/scratch/bcpi/cliu28/internal-tide-mixing $rundir4 > output_message/2D-idealized_tilt.run4.${SLURM_JOB_ID}.${SLURM_NODELIST}.log 2>&1 &

wait
tail -n 50 output_message/3D-idealized_tilt.run*.${SLURM_JOB_ID}.*.log
echo "All runs completed."
date

